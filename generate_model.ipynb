{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\dl_tools\\envs\\paddle_env\\lib\\site-packages\\matplotlib_inline\\config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "#导入要用到的模块\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练的mapper\n",
    "# train_mapper函数的作用是用来对训练集的图像进行处理修剪和数组变换，返回img数组和标签 \n",
    "# sample是一个python元组，里面保存着图片的地址和标签。 ('../images/face/zhangziyi/20181206145348.png', 2)\n",
    "def train_mapper(sample):\n",
    "    img, label = sample\n",
    "    # 进行图片的读取，由于数据集的像素维度各不相同，需要进一步处理对图像进行变换\n",
    "    img = paddle.dataset.image.load_image(img)       \n",
    "    # 进行了简单的图像变换，这里对图像进行crop修剪操作，输出img的维度为(3, 100, 100)\n",
    "    img = paddle.dataset.image.simple_transform(im=img,          # 输入图片是HWC   \n",
    "                                                resize_size=100, # 剪裁图片\n",
    "                                                crop_size=100, \n",
    "                                                is_color=True,  # 彩色图像\n",
    "                                                is_train=True)\n",
    "    # 将img数组进行进行归一化处理，得到0到1之间的数值\n",
    "    img= img.flatten().astype('float32')/255.0\n",
    "    return img, label\n",
    "# 对自定义数据集创建训练集train的reader\n",
    "def train_r(train_list, buffered_size=1024):\n",
    "    def reader():\n",
    "        \"\"\"\n",
    "        with 语句实质是上下文管理。\n",
    "        1、上下文管理协议。包含方法__enter__() 和 __exit__()，支持该协议对象要实现这两个方法。\n",
    "        2、上下文管理器，定义执行with语句时要建立的运行时上下文，负责执行with语句块上下文中的进入与退出操作。\n",
    "        3、进入上下文的时候执行__enter__方法，如果设置as var语句，var变量接受__enter__()方法返回值。\n",
    "        4、如果运行时发生了异常，就退出上下文管理器。调用管理器__exit__方法。\n",
    "        \"\"\" \n",
    "        \"\"\"\n",
    "        格式\n",
    "        with context [as var]:\n",
    "        pass\n",
    "        \"\"\"\n",
    "        with open(train_list, 'r') as f:\n",
    "            # 将train.list里面的标签和图片的地址方法一个list列表里面，中间用/t隔开'\n",
    "            # ../images/face/jiangwen/0b1937e2-f929-11e8-8a8a-005056c00008.jpg/t0'\n",
    "            lines = [line.strip() for line in f]\n",
    "            for line in lines:\n",
    "                # 图像的路径和标签是以\\t来分割的,所以我们在生成这个列表的时候,使用\\t就可以了\n",
    "                img_path, lab = line.strip().split('\\t')\n",
    "                # yield 的作用就是把一个函数变成一个 generator，\n",
    "                # 带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator，\n",
    "                # 调用 fab(5) 不会执行 fab 函数，而是返回一个 iterable 对象！\n",
    "                # 在 for 循环执行时，每次循环都会执行 fab 函数内部的代码，执行到 yield b 时，\n",
    "                # fab 函数就返回一个迭代值，下次迭代时，代码从 yield b 的下一条语句继续执行，\n",
    "                # 而函数的本地变量看起来和上次中断执行前是完全一样的，于是函数继续执行，直到再次遇到 yield\n",
    "                yield img_path, int(lab) \n",
    "    # 创建自定义数据训练集的train_reader\n",
    "    return paddle.reader.xmap_readers(train_mapper, reader,cpu_count(), buffered_size)\n",
    "\n",
    "# sample是一个python元组，里面保存着图片的地址和标签。 ('../images/face/zhangziyi/20181206145348.png', 2)\n",
    "def test_mapper(sample):\n",
    "    img, label = sample\n",
    "    img = paddle.dataset.image.load_image(img)\n",
    "    img = paddle.dataset.image.simple_transform(im=img, resize_size=100, crop_size=100, is_color=True, is_train=False)\n",
    "    img= img.flatten().astype('float32')/255.0\n",
    "    return img, label\n",
    "\n",
    "# 对自定义数据集创建验证集test的reader\n",
    "def test_r(test_list, buffered_size=1024):\n",
    "    def reader():\n",
    "        with open(test_list, 'r') as f:\n",
    "            lines = [line.strip() for line in f]\n",
    "            for line in lines:\n",
    "                #图像的路径和标签是以\\t来分割的,所以我们在生成这个列表的时候,使用\\t就可以了\n",
    "                img_path, lab = line.strip().split('\\t')\n",
    "                yield img_path, int(lab)\n",
    "\n",
    "    return paddle.reader.xmap_readers(test_mapper, reader,cpu_count(), buffered_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# 把图片数据生成reader\n",
    "trainer_reader = train_r(train_list=\"E:/VSCodeWorkSpace/face_recognize/face/trainer.list\")\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        reader=trainer_reader,buf_size=300),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "tester_reader = test_r(test_list=\"E:/VSCodeWorkSpace/face_recognize/face/test.list\")\n",
    "test_reader = paddle.batch(\n",
    "     tester_reader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([1.        , 1.        , 1.        , ..., 0.02352941, 0.02745098,\n",
      "       0.02745098], dtype=float32), 0), (array([1., 1., 1., ..., 1., 1., 1.], dtype=float32), 0), (array([0.7137255 , 0.6509804 , 0.65882355, ..., 0.02745098, 0.03921569,\n",
      "       0.05882353], dtype=float32), 0)]\n"
     ]
    }
   ],
   "source": [
    "train_data = paddle.batch(trainer_reader,\n",
    "                            batch_size=3)\n",
    "sampledata=next(train_data())\n",
    "print(sampledata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(image, type_size):\n",
    "    # 第一个卷积--池化层\n",
    "    conv_pool_1 = fluid.nets.simple_img_conv_pool(input=image, # 输入图像\n",
    "                                                       filter_size=3, # 滤波器的大小(3x3)\n",
    "                                                       num_filters=32, # filter的数量。它与输出的通道相同(32个特征)\n",
    "                                                       pool_size=2, # 池化层大小2*2\n",
    "                                                       pool_stride=2, # 池化层步长\n",
    "                                                       act='relu') # 激活类型\n",
    "    \n",
    "    # Dropout主要作用是减少过拟合，随机让某些权重不更新  \n",
    "    # Dropout是一种正则化技术，通过在训练过程中阻止神经元节点间的联合适应性来减少过拟合。\n",
    "    # 根据给定的丢弃概率dropout随机将一些神经元输出设置为0，其他的仍保持不变。\n",
    "    drop = fluid.layers.dropout(x=conv_pool_1, dropout_prob=0.5)\n",
    "    \n",
    "    # 第二个卷积--池化层\n",
    "    conv_pool_2 = fluid.nets.simple_img_conv_pool(input=drop,\n",
    "                                                       filter_size=3,\n",
    "                                                       num_filters=64,\n",
    "                                                       pool_size=2,\n",
    "                                                       pool_stride=2,\n",
    "                                                       act='relu')\n",
    "    # 减少过拟合，随机让某些权重不更新                                                   \n",
    "    drop = fluid.layers.dropout(x=conv_pool_2, dropout_prob=0.5)\n",
    "    \n",
    "    # 第三个卷积--池化层\n",
    "    conv_pool_3 = fluid.nets.simple_img_conv_pool(input=drop,\n",
    "                                                       filter_size=3,\n",
    "                                                       num_filters=64,\n",
    "                                                       pool_size=2,\n",
    "                                                       pool_stride=2,\n",
    "                                                       act='relu')\n",
    "    # 减少过拟合，随机让某些权重不更新                                                   \n",
    "    drop = fluid.layers.dropout(x=conv_pool_3, dropout_prob=0.5)\n",
    "    \n",
    "    # 全连接层\n",
    "    fc = fluid.layers.fc(input=drop, size=512, act='relu')\n",
    "    # 减少过拟合，随机让某些权重不更新                                                   \n",
    "    drop =  fluid.layers.dropout(x=fc, dropout_prob=0.5)                                                   \n",
    "    # 输出层 以softmax为激活函数的全连接输出层，输出层的大小为图像类别type_size个数\n",
    "    predict = fluid.layers.fc(input=drop,size=type_size,act='softmax')\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_bn_drop(image, type_size):  \n",
    "    def conv_block(ipt, num_filter, groups, dropouts):\n",
    "        return fluid.nets.img_conv_group(\n",
    "            input=ipt, # 具有[N，C，H，W]格式的输入图像\n",
    "            pool_size=2,\n",
    "            pool_stride=2,\n",
    "            conv_num_filter=[num_filter] * groups, # 过滤器个数\n",
    "            conv_filter_size=3, # 过滤器大小\n",
    "            conv_act='relu',\n",
    "            conv_with_batchnorm=True, # 表示在 Conv2d Layer 之后是否使用 BatchNorm\n",
    "            conv_batchnorm_drop_rate=dropouts,# 表示 BatchNorm 之后的 Dropout Layer 的丢弃概率\n",
    "            pool_type='max') # 最大池化\n",
    "\n",
    "    conv1 = conv_block(image, 64, 2, [0.0, 0])\n",
    "    conv2 = conv_block(conv1, 128, 2, [0.0, 0])\n",
    "    conv3 = conv_block(conv2, 256, 3, [0.0, 0.0, 0])\n",
    "    conv4 = conv_block(conv3, 512, 3, [0.0, 0.0, 0])\n",
    "    conv5 = conv_block(conv4, 512, 3, [0.0, 0.0, 0])\n",
    "\n",
    "    drop = fluid.layers.dropout(x=conv5, dropout_prob=0.5)\n",
    "    fc1 = fluid.layers.fc(input=drop, size=512, act=None)\n",
    "    \n",
    "    bn = fluid.layers.batch_norm(input=fc1, act='relu')\n",
    "    drop2 = fluid.layers.dropout(x=bn, dropout_prob=0.0)\n",
    "    fc2 = fluid.layers.fc(input=drop2, size=512, act=None)\n",
    "    predict = fluid.layers.fc(input=fc2, size=type_size, act='softmax')\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_shape: (-1, 3, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "paddle.enable_static()\n",
    "image = fluid.layers.data(name='image', shape=[3, 100, 100], dtype='float32') #[3, 100, 100]，表示为三通道，100*100的RGB图\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "print('image_shape:',image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## 获取分类器，用cnn或者vgg网络进行分类type_size要和训练的类别一致 ########\n",
    "predict = convolutional_neural_network(image=image, type_size=4)\n",
    "#predict = vgg_bn_drop(image=image, type_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取损失函数和准确率\n",
    "cost = fluid.layers.cross_entropy(input=predict, label=label)\n",
    "# 计算cost中所有元素的平均值\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "#计算准确率\n",
    "accuracy = fluid.layers.accuracy(input=predict, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'paddle.fluid.framework.Variable'>\n"
     ]
    }
   ],
   "source": [
    "# 定义优化方法\n",
    "optimizer = fluid.optimizer.Adam(learning_rate=0.001)    # Adam是一阶基于梯度下降的算法，基于自适应低阶矩估计该函数实现了自适应矩估计优化器\n",
    "\n",
    "optimizer.minimize(avg_cost)                             # 取局部最优化的平均损失\n",
    "print(type(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用CPU进行训练\n",
    "place = fluid.CPUPlace()\n",
    "# 创建一个executor\n",
    "exe = fluid.Executor(place)\n",
    "# 对program进行参数初始化1.网络模型2.损失函数3.优化函数\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入数据的维度,DataFeeder 负责将reader(读取器)返回的数据转成一种特殊的数据结构，使它们可以输入到 Executor\n",
    "feeder = fluid.DataFeeder(feed_list=[image, label], place=place)#定义输入数据的维度，第一个是图片数据，第二个是图片对应的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_iter=0\n",
    "all_train_iters=[]\n",
    "all_train_costs=[]\n",
    "all_train_accs=[]\n",
    "\n",
    "def draw_train_process(title,iters,costs,accs,label_cost,lable_acc):\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=20)\n",
    "    plt.ylabel(\"cost/acc\", fontsize=20)\n",
    "    plt.plot(iters, costs,color='red',label=label_cost) \n",
    "    plt.plot(iters, accs,color='green',label=lable_acc) \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "\n",
      "Pass 0, Step 0, Cost 1.381229, Acc 0.343750\n",
      "Test:0, Cost:1.24993, ACC:0.25000\n",
      "\n",
      "Pass 1, Step 0, Cost 0.792480, Acc 0.656250\n",
      "Test:1, Cost:0.69574, ACC:0.82812\n",
      "\n",
      "Pass 2, Step 0, Cost 0.937821, Acc 0.500000\n",
      "Test:2, Cost:0.51516, ACC:0.82812\n",
      "\n",
      "Pass 3, Step 0, Cost 0.976537, Acc 0.562500\n",
      "Test:3, Cost:1.11571, ACC:0.35938\n",
      "\n",
      "Pass 4, Step 0, Cost 0.765808, Acc 0.687500\n",
      "Test:4, Cost:0.48967, ACC:0.78125\n",
      "\n",
      "Pass 5, Step 0, Cost 0.688380, Acc 0.781250\n",
      "Test:5, Cost:0.30806, ACC:0.89062\n",
      "\n",
      "Pass 6, Step 0, Cost 0.615456, Acc 0.781250\n",
      "Test:6, Cost:0.26136, ACC:0.87500\n",
      "\n",
      "Pass 7, Step 0, Cost 0.558228, Acc 0.718750\n",
      "Test:7, Cost:0.23083, ACC:0.89062\n",
      "\n",
      "Pass 8, Step 0, Cost 0.745376, Acc 0.687500\n",
      "Test:8, Cost:0.29366, ACC:0.87500\n",
      "\n",
      "Pass 9, Step 0, Cost 0.527559, Acc 0.812500\n",
      "Test:9, Cost:0.23154, ACC:0.90625\n",
      "\n",
      "Pass 10, Step 0, Cost 0.463097, Acc 0.843750\n",
      "Test:10, Cost:0.20753, ACC:0.89062\n",
      "\n",
      "Pass 11, Step 0, Cost 0.435301, Acc 0.781250\n",
      "Test:11, Cost:0.20201, ACC:0.95312\n",
      "\n",
      "Pass 12, Step 0, Cost 0.618859, Acc 0.750000\n",
      "Test:12, Cost:0.16521, ACC:0.92188\n",
      "\n",
      "Pass 13, Step 0, Cost 0.552383, Acc 0.750000\n",
      "Test:13, Cost:0.24502, ACC:0.87500\n",
      "\n",
      "Pass 14, Step 0, Cost 0.349700, Acc 0.875000\n",
      "Test:14, Cost:0.19477, ACC:0.92188\n",
      "\n",
      "Pass 15, Step 0, Cost 0.227704, Acc 0.937500\n",
      "Test:15, Cost:0.16077, ACC:0.95312\n",
      "\n",
      "Pass 16, Step 0, Cost 0.256159, Acc 0.906250\n",
      "Test:16, Cost:0.19034, ACC:0.92188\n",
      "\n",
      "Pass 17, Step 0, Cost 0.329437, Acc 0.843750\n",
      "Test:17, Cost:0.09613, ACC:0.96875\n",
      "\n",
      "Pass 18, Step 0, Cost 0.386514, Acc 0.781250\n",
      "Test:18, Cost:0.15563, ACC:0.95312\n",
      "\n",
      "Pass 19, Step 0, Cost 0.191689, Acc 0.875000\n",
      "Test:19, Cost:0.19702, ACC:0.89062\n"
     ]
    }
   ],
   "source": [
    "# 训练的轮数\n",
    "EPOCH_NUM = 20\n",
    "print('开始训练...')\n",
    "#两种方法，用两个不同的路径分别保存训练的模型\n",
    "#model_save_dir = \"/home/aistudio/data/model_vgg\"\n",
    "model_save_dir = \"E:/VSCodeWorkSpace/face_recognize/data/model_cnn\"\n",
    "for pass_id in range(EPOCH_NUM):\n",
    "    train_cost = 0\n",
    "    for batch_id, data in enumerate(train_reader()):                         #遍历train_reader的迭代器，并为数据加上索引batch_id\n",
    "        train_cost, train_acc = exe.run(\n",
    "            program=fluid.default_main_program(),                            #运行主程序\n",
    "            feed=feeder.feed(data),                                          #喂入一个batch的数据\n",
    "            fetch_list=[avg_cost, accuracy])                                 #fetch均方误差和准确率\n",
    "        \n",
    "        all_train_iter=all_train_iter+BATCH_SIZE\n",
    "        all_train_iters.append(all_train_iter)\n",
    "        all_train_costs.append(train_cost[0])\n",
    "        all_train_accs.append(train_acc[0])\n",
    "       \n",
    "       \n",
    "        if batch_id % 10 == 0:                                               #每10次batch打印一次训练、进行一次测试\n",
    "            print(\"\\nPass %d, Step %d, Cost %f, Acc %f\" % \n",
    "            (pass_id, batch_id, train_cost[0], train_acc[0]))\n",
    "    # 开始测试\n",
    "    test_accs = []                                                            #测试的损失值\n",
    "    test_costs = []                                                           #测试的准确率\n",
    "    # 每训练一轮 进行一次测试\n",
    "    for batch_id, data in enumerate(test_reader()):                           # 遍历test_reader\n",
    "         test_cost, test_acc = exe.run(program=fluid.default_main_program(),  # #运行测试主程序\n",
    "                                       feed=feeder.feed(data),                #喂入一个batch的数据\n",
    "                                       fetch_list=[avg_cost, accuracy])       #fetch均方误差、准确率\n",
    "         test_accs.append(test_acc[0])                                        #记录每个batch的误差\n",
    "         test_costs.append(test_cost[0])                                      #记录每个batch的准确率\n",
    "\n",
    "   # 求测试结果的平均值\n",
    "    test_cost = (sum(test_costs) / len(test_costs))                           # 每轮的平均误差\n",
    "    test_acc = (sum(test_accs) / len(test_accs))                              # 每轮的平均准确率\n",
    "    print('Test:%d, Cost:%0.5f, ACC:%0.5f' % (pass_id, test_cost, test_acc))\n",
    "    \n",
    "   \n",
    "    # 如果保存路径不存在就创建\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    # 保存训练的模型，executor 把所有相关参数保存到 dirname 中\n",
    "    fluid.io.save_inference_model(dirname=model_save_dir, \n",
    "                                    feeded_var_names=[\"image\"],\n",
    "                                    target_vars=[predict],\n",
    "                                    executor=exe)\n",
    "                                    \n",
    "draw_train_process(\"training\",all_train_iters,all_train_costs,all_train_accs,\"trainning cost\",\"trainning acc\")\n",
    "\n",
    "print('训练模型保存完成！')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af14062252bd6bcb1df7c21e401e503e612a70b8ca55f72b838cc0e12516528c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('paddle_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
